{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "\u001b[31m  Could not find a version that satisfies the requirement mediapipe (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for mediapipe\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.3.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.8.9-cp37-cp37m-macosx_10_15_x86_64.whl (33.5 MB)\n",
      "Collecting opencv-contrib-python\n",
      "  Using cached opencv_contrib_python-4.5.4.58-cp37-cp37m-macosx_10_15_x86_64.whl (54.5 MB)\n",
      "Requirement already satisfied: six in /Users/stella/opt/anaconda3/lib/python3.7/site-packages (from mediapipe) (1.14.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Users/stella/opt/anaconda3/lib/python3.7/site-packages (from mediapipe) (19.3.0)\n",
      "Requirement already satisfied: wheel in /Users/stella/opt/anaconda3/lib/python3.7/site-packages (from mediapipe) (0.34.2)\n",
      "Requirement already satisfied: matplotlib in /Users/stella/opt/anaconda3/lib/python3.7/site-packages (from mediapipe) (3.1.3)\n",
      "Collecting protobuf>=3.11.4\n",
      "  Using cached protobuf-3.19.1-cp37-cp37m-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "Collecting absl-py\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: numpy in /Users/stella/opt/anaconda3/lib/python3.7/site-packages (from mediapipe) (1.18.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/stella/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->mediapipe) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/stella/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->mediapipe) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/stella/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/stella/opt/anaconda3/lib/python3.7/site-packages (from matplotlib->mediapipe) (2.8.1)\n",
      "Requirement already satisfied: setuptools in /Users/stella/opt/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (46.0.0.post20200309)\n",
      "Installing collected packages: protobuf, opencv-contrib-python, absl-py, mediapipe\n",
      "Successfully installed absl-py-1.0.0 mediapipe-0.8.9 opencv-contrib-python-4.5.4.58 protobuf-3.19.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mediapipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Video feed\n",
    "cap =cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    cv2.imshow(\"Mediapipe Feed\", frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord ('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() \n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Make Dtections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap =cv2.VideoCapture(0)\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        #Make detection\n",
    "        results = pose.process(image)\n",
    "        print (results)\n",
    "        # Recolor image to BGR\n",
    "        image.flags.writeable =True\n",
    "        image= cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # print (results)\n",
    "        # cv2.imshow(\"Mediapipe Feed\", frame)\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks (image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                   #change color\n",
    "                                 # mp_drawing.DrawingSpec(color = (245,117,66), thickness=2, circle_radius=2),\n",
    "                                 # mp_drawing.DrawingSpec(color = (245,66,230), thickness=2, circle_radius=2)\n",
    "                                  \n",
    "                                  )\n",
    "        cv2.imshow(\"Mediapipe Feed\", image)\n",
    "        \n",
    "      \n",
    "    \n",
    "    \n",
    "        if cv2.waitKey(10) & 0xFF == ord ('q'):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() \n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "landmark {\n",
       "  x: 0.4882786273956299\n",
       "  y: 0.5758025646209717\n",
       "  z: -0.8444331884384155\n",
       "  visibility: 0.9984613656997681\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5082250237464905\n",
       "  y: 0.5152264833450317\n",
       "  z: -0.7962484955787659\n",
       "  visibility: 0.9971528053283691\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5213283896446228\n",
       "  y: 0.5162878632545471\n",
       "  z: -0.7965258359909058\n",
       "  visibility: 0.9977959990501404\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5308437347412109\n",
       "  y: 0.51827073097229\n",
       "  z: -0.7966697812080383\n",
       "  visibility: 0.9966092109680176\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4635164737701416\n",
       "  y: 0.5189052820205688\n",
       "  z: -0.803973376750946\n",
       "  visibility: 0.9976837038993835\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4476352334022522\n",
       "  y: 0.5239182114601135\n",
       "  z: -0.8038077354431152\n",
       "  visibility: 0.9983466863632202\n",
       "}\n",
       "landmark {\n",
       "  x: 0.43349456787109375\n",
       "  y: 0.5291008949279785\n",
       "  z: -0.8042452931404114\n",
       "  visibility: 0.9980988502502441\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5490063428878784\n",
       "  y: 0.5544039607048035\n",
       "  z: -0.467795193195343\n",
       "  visibility: 0.997592031955719\n",
       "}\n",
       "landmark {\n",
       "  x: 0.41862815618515015\n",
       "  y: 0.5670891404151917\n",
       "  z: -0.4873102307319641\n",
       "  visibility: 0.9990991353988647\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5172920227050781\n",
       "  y: 0.6502943634986877\n",
       "  z: -0.7171395421028137\n",
       "  visibility: 0.9980711936950684\n",
       "}\n",
       "landmark {\n",
       "  x: 0.45928770303726196\n",
       "  y: 0.6518420577049255\n",
       "  z: -0.7234842777252197\n",
       "  visibility: 0.9991215467453003\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6747761368751526\n",
       "  y: 0.9071077704429626\n",
       "  z: -0.2332172393798828\n",
       "  visibility: 0.9777615070343018\n",
       "}\n",
       "landmark {\n",
       "  x: 0.3173152804374695\n",
       "  y: 0.9186574220657349\n",
       "  z: -0.3134995102882385\n",
       "  visibility: 0.987276554107666\n",
       "}\n",
       "landmark {\n",
       "  x: 0.8014479875564575\n",
       "  y: 1.2513229846954346\n",
       "  z: -0.38757115602493286\n",
       "  visibility: 0.04500069096684456\n",
       "}\n",
       "landmark {\n",
       "  x: 0.20698101818561554\n",
       "  y: 1.3724491596221924\n",
       "  z: -0.40887874364852905\n",
       "  visibility: 0.1376064121723175\n",
       "}\n",
       "landmark {\n",
       "  x: 0.7666147351264954\n",
       "  y: 1.3494651317596436\n",
       "  z: -0.8502777218818665\n",
       "  visibility: 0.03205857053399086\n",
       "}\n",
       "landmark {\n",
       "  x: 0.2729640305042267\n",
       "  y: 1.623226284980774\n",
       "  z: -0.8780158162117004\n",
       "  visibility: 0.03786015138030052\n",
       "}\n",
       "landmark {\n",
       "  x: 0.7730239629745483\n",
       "  y: 1.3997639417648315\n",
       "  z: -0.9678950309753418\n",
       "  visibility: 0.04852859675884247\n",
       "}\n",
       "landmark {\n",
       "  x: 0.2774398922920227\n",
       "  y: 1.73056161403656\n",
       "  z: -0.9940714836120605\n",
       "  visibility: 0.04934746026992798\n",
       "}\n",
       "landmark {\n",
       "  x: 0.7465208768844604\n",
       "  y: 1.3292382955551147\n",
       "  z: -0.9887259602546692\n",
       "  visibility: 0.07153424620628357\n",
       "}\n",
       "landmark {\n",
       "  x: 0.31139686703681946\n",
       "  y: 1.6906498670578003\n",
       "  z: -1.0297361612319946\n",
       "  visibility: 0.07981567829847336\n",
       "}\n",
       "landmark {\n",
       "  x: 0.728907585144043\n",
       "  y: 1.3238581418991089\n",
       "  z: -0.8834460973739624\n",
       "  visibility: 0.06581884622573853\n",
       "}\n",
       "landmark {\n",
       "  x: 0.3146919906139374\n",
       "  y: 1.6483675241470337\n",
       "  z: -0.908776581287384\n",
       "  visibility: 0.07550081610679626\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6090191602706909\n",
       "  y: 1.7470346689224243\n",
       "  z: -0.023707997053861618\n",
       "  visibility: 0.0003778066602535546\n",
       "}\n",
       "landmark {\n",
       "  x: 0.37489011883735657\n",
       "  y: 1.7632651329040527\n",
       "  z: 0.02786957286298275\n",
       "  visibility: 0.00034007613430731\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6194307804107666\n",
       "  y: 2.4022669792175293\n",
       "  z: -0.09027337282896042\n",
       "  visibility: 0.001410988625138998\n",
       "}\n",
       "landmark {\n",
       "  x: 0.40107470750808716\n",
       "  y: 2.4067301750183105\n",
       "  z: -0.10629217326641083\n",
       "  visibility: 0.00042268651304766536\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6343592405319214\n",
       "  y: 3.0040812492370605\n",
       "  z: 0.29919320344924927\n",
       "  visibility: 0.0001052414663718082\n",
       "}\n",
       "landmark {\n",
       "  x: 0.41947364807128906\n",
       "  y: 3.006782054901123\n",
       "  z: 0.14821787178516388\n",
       "  visibility: 1.881386742752511e-05\n",
       "}\n",
       "landmark {\n",
       "  x: 0.6401740312576294\n",
       "  y: 3.1027300357818604\n",
       "  z: 0.31131863594055176\n",
       "  visibility: 9.298993245465681e-05\n",
       "}\n",
       "landmark {\n",
       "  x: 0.41667866706848145\n",
       "  y: 3.1102521419525146\n",
       "  z: 0.15726444125175476\n",
       "  visibility: 3.381379065103829e-05\n",
       "}\n",
       "landmark {\n",
       "  x: 0.5983571410179138\n",
       "  y: 3.200111150741577\n",
       "  z: -0.16460444033145905\n",
       "  visibility: 0.00016271155618596822\n",
       "}\n",
       "landmark {\n",
       "  x: 0.4597932696342468\n",
       "  y: 3.1840834617614746\n",
       "  z: -0.34788545966148376\n",
       "  visibility: 0.00011806718976004049\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show landmarks\n",
    "results.pose_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({(0, 1),\n",
       "           (0, 4),\n",
       "           (1, 2),\n",
       "           (2, 3),\n",
       "           (3, 7),\n",
       "           (4, 5),\n",
       "           (5, 6),\n",
       "           (6, 8),\n",
       "           (9, 10),\n",
       "           (11, 12),\n",
       "           (11, 13),\n",
       "           (11, 23),\n",
       "           (12, 14),\n",
       "           (12, 24),\n",
       "           (13, 15),\n",
       "           (14, 16),\n",
       "           (15, 17),\n",
       "           (15, 19),\n",
       "           (15, 21),\n",
       "           (16, 18),\n",
       "           (16, 20),\n",
       "           (16, 22),\n",
       "           (17, 19),\n",
       "           (18, 20),\n",
       "           (23, 24),\n",
       "           (23, 25),\n",
       "           (24, 26),\n",
       "           (25, 27),\n",
       "           (26, 28),\n",
       "           (27, 29),\n",
       "           (27, 31),\n",
       "           (28, 30),\n",
       "           (28, 32),\n",
       "           (29, 31),\n",
       "           (30, 32)})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show which landmarks connect which\n",
    "# Need to improve\n",
    "mp_pose.POSE_CONNECTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Determining Joints\n",
    "\n",
    "![title](https://google.github.io/mediapipe/images/mobile/pose_tracking_full_body_landmarks.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap =cv2.VideoCapture(0)\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        #Make detection\n",
    "        results = pose.process(image)\n",
    "        \n",
    "        # Recolor image to BGR\n",
    "        image.flags.writeable =True\n",
    "        image= cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # print (results)\n",
    "        # cv2.imshow(\"Mediapipe Feed\", frame)\n",
    "        \n",
    "        # Extrack landmarks\n",
    "        \n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "           # print (landmarks)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks (image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                   #change color\n",
    "                                 # mp_drawing.DrawingSpec(color = (245,117,66), thickness=2, circle_radius=2),\n",
    "                                 # mp_drawing.DrawingSpec(color = (245,66,230), thickness=2, circle_radius=2)\n",
    "                                  \n",
    "                                  )\n",
    "        cv2.imshow(\"Mediapipe Feed\", image)\n",
    "        \n",
    "      \n",
    "    \n",
    "    \n",
    "        if cv2.waitKey(10) & 0xFF == ord ('q'):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() \n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoseLandmark.NOSE\n",
      "PoseLandmark.LEFT_EYE_INNER\n",
      "PoseLandmark.LEFT_EYE\n",
      "PoseLandmark.LEFT_EYE_OUTER\n",
      "PoseLandmark.RIGHT_EYE_INNER\n",
      "PoseLandmark.RIGHT_EYE\n",
      "PoseLandmark.RIGHT_EYE_OUTER\n",
      "PoseLandmark.LEFT_EAR\n",
      "PoseLandmark.RIGHT_EAR\n",
      "PoseLandmark.MOUTH_LEFT\n",
      "PoseLandmark.MOUTH_RIGHT\n",
      "PoseLandmark.LEFT_SHOULDER\n",
      "PoseLandmark.RIGHT_SHOULDER\n",
      "PoseLandmark.LEFT_ELBOW\n",
      "PoseLandmark.RIGHT_ELBOW\n",
      "PoseLandmark.LEFT_WRIST\n",
      "PoseLandmark.RIGHT_WRIST\n",
      "PoseLandmark.LEFT_PINKY\n",
      "PoseLandmark.RIGHT_PINKY\n",
      "PoseLandmark.LEFT_INDEX\n",
      "PoseLandmark.RIGHT_INDEX\n",
      "PoseLandmark.LEFT_THUMB\n",
      "PoseLandmark.RIGHT_THUMB\n",
      "PoseLandmark.LEFT_HIP\n",
      "PoseLandmark.RIGHT_HIP\n",
      "PoseLandmark.LEFT_KNEE\n",
      "PoseLandmark.RIGHT_KNEE\n",
      "PoseLandmark.LEFT_ANKLE\n",
      "PoseLandmark.RIGHT_ANKLE\n",
      "PoseLandmark.LEFT_HEEL\n",
      "PoseLandmark.RIGHT_HEEL\n",
      "PoseLandmark.LEFT_FOOT_INDEX\n",
      "PoseLandmark.RIGHT_FOOT_INDEX\n"
     ]
    }
   ],
   "source": [
    "for lndmrk in mp_pose.PoseLandmark:\n",
    "    print(lndmrk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculate Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle (a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1],a[0]-b[0])\n",
    "    angle = np.abs(radians* 180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.6277793645858765, 0.690631628036499],\n",
       " [0.7427674531936646, 1.0064469575881958],\n",
       " [0.864712119102478, 1.3920358419418335])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoulder,elbow,wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177.54333204583983"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_angle(shoulder,elbow,wrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451, 477)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(np.multiply(elbow, [640,480]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# angle visible\n",
    "\n",
    "cap =cv2.VideoCapture(0)\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        #Make detection\n",
    "        results = pose.process(image)\n",
    "        \n",
    "        # Recolor image to BGR\n",
    "        image.flags.writeable =True\n",
    "        image= cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # print (results)\n",
    "        # cv2.imshow(\"Mediapipe Feed\", frame)\n",
    "        \n",
    "        # Extrack landmarks\n",
    "        \n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "           # print (landmarks)\n",
    "            \n",
    "            #Get coordinates\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "        \n",
    "            # Calculate angle\n",
    "            angle=calculate_angle(shoulder,elbow,wrist)\n",
    "            position=tuple(np.multiply(elbow, [640,480]).astype(int))\n",
    "            #position=(500, 500)\n",
    "            font =cv2.FONT_HERSHEY_SIMPLEX\n",
    "            # Visualize angle\n",
    "            cv2.putText(image, str(angle),position,font,0.5,(255,255,255),2,cv2.LINE_AA)\n",
    "                       \n",
    "                    \n",
    "            #print (landmarks)\n",
    "        \n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks (image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                   #change color\n",
    "                                 # mp_drawing.DrawingSpec(color = (245,117,66), thickness=2, circle_radius=2),\n",
    "                                 # mp_drawing.DrawingSpec(color = (245,66,230), thickness=2, circle_radius=2)\n",
    "                                  \n",
    "                                  )\n",
    "        cv2.imshow(\"Mediapipe Feed\", image)\n",
    "        \n",
    "      \n",
    "    \n",
    "    \n",
    "        if cv2.waitKey(10) & 0xFF == ord ('q'):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() \n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Curl Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap =cv2.VideoCapture(0)\n",
    "\n",
    "# Curl counter variables\n",
    "\n",
    "counter=0\n",
    "stage = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        #Make detection\n",
    "        results = pose.process(image)\n",
    "        \n",
    "        # Recolor image to BGR\n",
    "        image.flags.writeable =True\n",
    "        image= cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # print (results)\n",
    "        # cv2.imshow(\"Mediapipe Feed\", frame)\n",
    "        \n",
    "        # Extrack landmarks\n",
    "        \n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "           # print (landmarks)\n",
    "            \n",
    "            #Get coordinates\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "        \n",
    "            # Calculate angle\n",
    "            angle=calculate_angle(shoulder,elbow,wrist)\n",
    "            \n",
    "            \n",
    "            # Curl counter logic\n",
    "            if angle > 160:\n",
    "                stage =\"down\"\n",
    "            if angle < 30 and stage == 'down':\n",
    "                stage =\"up\"\n",
    "                counter +=1\n",
    "               # print (counter)\n",
    "            \n",
    "     # Visualize angle\n",
    "            \n",
    "                \n",
    "            #position=tuple(np.multiply(elbow, [640,480]).astype(int))\n",
    "            position=(100, 100)\n",
    "            font =cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(image, str(counter),position,font,2,(255,255,255),2,cv2.LINE_AA)\n",
    "                                      \n",
    "            #print (landmarks)\n",
    "            \n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks (image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                   #change color\n",
    "                                 # mp_drawing.DrawingSpec(color = (245,117,66), thickness=2, circle_radius=2),\n",
    "                                 # mp_drawing.DrawingSpec(color = (245,66,230), thickness=2, circle_radius=2)\n",
    "                                  \n",
    "                                  )\n",
    "        cv2.imshow(\"Mediapipe Feed\", image)\n",
    "        \n",
    "      \n",
    "    \n",
    "    \n",
    "        if cv2.waitKey(10) & 0xFF == ord ('q'):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() \n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
