# 进度

# 第一周 11.8-11.12

安装配置，放弃 Openpose，初次尝试 Mediapipe

# 第二周 11.15-11.19

跟着教程用 pyhton做了写了可以计算举手次数的code。

## 底层逻辑

1. 用 opencv 打开摄像头，注意 mac 和 window 相比，多了一句代码
2. 把得到的数据流（image）从 BGR 转换成 RGB，因为 Meidapipe 只读取 RGB
3. 用 SSD 的方法来确定目标
4. Mediapipe 库中定义了 Landmark ，通过这样来取得身体点
5. 标记点
6. 用 ROI 的方式确定下个 image 的点
7. 连接各个点
8. 再把 RGB 转换成 BGR（输出）
9. 通过连接的线，来计算运动角度
10. 通过角度来确定姿势
11. 通过姿势变化的判断来确定举手次数

## 遇到的问题

1.  本来以为是我距离远了有些举手次数识别不到，结果和导师一起分析，因为在远处，我的身体构架也是能够识别的，也就是说，连接的线及形成的角度也是能够识别。和远近就没有关系了

2. 然后发现有几帧我的手已经抬起来了，但是没有识别到，构架还是停在原地，再观察，可能与我穿的白衣服和白墙有关，机器识别我的衣服和白墙颜色一样，出现错误，这个概率很大

3. 衣服相近，与环境探测不准确可以用 Camara 来改善（具体是什么 Camara，忘记了，好像是和温度有关）

4. 也有可能是 todside 死角

5. 也或许是我的角度设定的范围太小了。或许 360 度更好，不要再 180 之类的，可以有四个 象限

6. 想要知道 xyz,具体是什么，可否通过 再加一个数值来改进（现在只用了 xyz）

   

## 接下来研究的方向

1. 在 SSD 上加上 kalmanfilter 
   1. kalmanfilter 对于手部滑动这种固定的，有规律的探测很有用处 (连续的动作)
   2. 所以要根据不同的动作加上不同的 filter
   3. 先用 kalmanfilter 在 Mediapipe 上做出来，再看看其他的 filter
   
2. 为什么大家都喜欢转换成 RGB, 而不直接用，从 Opencv 里面出来的 BGR image

3. （这段有些没听懂）ROI 抓取得 sample 有些 verschieben 点。是说，有 verschieben 的问题还是 通过点的 verschieben 来确定运动规律。或者两点都有讲到，但是我记忆搞混了时间了

4. 之前的改进探测准确度

   

# 第三周

